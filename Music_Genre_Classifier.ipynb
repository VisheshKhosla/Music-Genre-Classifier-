{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa \n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"genres\"\n",
    "json_path=\"json_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR=22050\n",
    "dur=30\n",
    "total_samples=SR*dur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_str(s):\n",
    "    ans=\"\"\n",
    "    for i in range(len(s)):\n",
    "        ans=s[i]+ans\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_mfcc(data_path,json_path,n_mfcc=13,n_fft=2048,hop_length=512,num_segments=10):\n",
    "    \n",
    "    data={\n",
    "        \"mapping\":[],  # Mapping of genre with the index\n",
    "        \"mfcc\":[],\n",
    "        \"labels\":[]\n",
    "    }\n",
    "    \n",
    "    for count,(dirpath,dirnames,filenames) in enumerate(os.walk(data_path)):\n",
    "        if dirpath==data_path:\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            # Extracting the genre\n",
    "            \n",
    "            gen=\"\"\n",
    "            dirgen=reverse_str(dirpath)\n",
    "            for i in range(len(dirgen)):\n",
    "                if(dirgen[i]==\"\\\\\"):\n",
    "                   break\n",
    "                else:\n",
    "                   gen+=dirgen[i]\n",
    "            print(reverse_str(gen))\n",
    "            data[\"mapping\"].append(reverse_str(gen))\n",
    "            \n",
    "            # Now for each genre exploring all of the files\n",
    "    \n",
    "            for file in filenames:\n",
    "            \n",
    "                # loading audio file\n",
    "                \n",
    "                file_path=os.path.join(dirpath,file)\n",
    "                signal,sr=librosa.load(file_path,SR)\n",
    "                \n",
    "                # Chopping off into segments\n",
    "                \n",
    "                num_samples_per_segment=total_samples//num_segments\n",
    "                num_mfcc_vec_seg=math.ceil(num_samples_per_segment/hop_length)\n",
    "                \n",
    "                for segment in range(num_segments):\n",
    "                    \n",
    "                    start_seg=num_samples_per_segment*segment\n",
    "                    end_seg=start_seg+num_samples_per_segment\n",
    "                    mfcc_seg=librosa.feature.mfcc(signal[start_seg:end_seg],sr=SR,n_fft=n_fft,n_mfcc=n_mfcc,hop_length=hop_length)\n",
    "                    mfcc_seg=mfcc_seg.T \n",
    "                    \n",
    "                    # Stroring the mfcc if it has the expected length\n",
    "                    \n",
    "                    if len(mfcc_seg)==num_mfcc_vec_seg:\n",
    "                        data[\"mfcc\"].append(mfcc_seg.tolist())\n",
    "                        data[\"labels\"].append(count-1) \n",
    "    \n",
    "    with open(json_path,\"w\") as fp:\n",
    "        json.dump(data,fp,indent=4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blues\n",
      "classical\n",
      "country\n",
      "disco\n",
      "hiphop\n",
      "jazz\n",
      "metal\n",
      "pop\n",
      "reggae\n",
      "rock\n"
     ]
    }
   ],
   "source": [
    "prepare_data_mfcc(data_path,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file=open(json_path)\n",
    "data=json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "9996\n",
      "9996\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "# Confirming the shapes of data\n",
    "\n",
    "print(len(data[\"mapping\"]))\n",
    "print(len(data[\"mfcc\"]))\n",
    "print(len(data[\"labels\"])) \n",
    "print(len(data[\"mfcc\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Train_Data= 7996\n",
      "Size of Test_Data= 2000\n"
     ]
    }
   ],
   "source": [
    "# Train_Test Split\n",
    "\n",
    "X_Train,X_Test,Y_Train,Y_Test=model_selection.train_test_split(data[\"mfcc\"],data[\"labels\"],test_size=0.2)\n",
    "print(\"Size of Train_Data=\",len(X_Train))\n",
    "print(\"Size of Test_Data=\",len(X_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7996, 130, 13)\n",
      "(2000, 130, 13)\n",
      "(2000, 130, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "# Since CNN expects a 3rd dimension i.e the depth\n",
    "\n",
    "np_arr_train=np.array(X_Train)\n",
    "print(np_arr_train.shape)\n",
    "np_arr_train=np_arr_train.reshape(7996,130,13,1)\n",
    "\n",
    "np_arr_test=np.array(X_Test)\n",
    "print(np_arr_test.shape)\n",
    "\n",
    "np_arr_test=np_arr_test.reshape(2000,130,13,1)\n",
    "print(np_arr_test.shape)\n",
    "\n",
    "X_Train=np_arr_train\n",
    "X_Test=np_arr_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Architecture of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_architecture(data_shape):\n",
    "    model=keras.Sequential()\n",
    "    print(data_shape)\n",
    "    # 1st Convolutional Layer\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(32,(3,3),activation=\"relu\",input_shape=data_shape,data_format=\"channels_last\"))\n",
    "    model.add(keras.layers.MaxPool2D((3,3),strides=(2,2),padding=\"same\"))\n",
    "    \n",
    "    #2nd Convolutional Layer\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(32,(3,3),activation=\"relu\",data_format=\"channels_last\"))\n",
    "    model.add(keras.layers.MaxPool2D((3,3),strides=(2,2),padding=\"same\"))\n",
    "    \n",
    "    # Flattening the data\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    \n",
    "    # Dense Layer\n",
    "    \n",
    "    model.add(keras.layers.Dense(32,activation=\"relu\"))\n",
    "    \n",
    "    # Dropout\n",
    "    \n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    \n",
    "    # Output Layer\n",
    "    \n",
    "    model.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 13, 1)\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=build_architecture((130,13,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer=keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# I have used sparse categorical cross entropy because we don't have to provide labels as one hot encoding in this\n",
    "\n",
    "model.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Validation Data from Train Data\n",
    "\n",
    "X_Train,X_Valid,Y_Train,Y_Valid=model_selection.train_test_split(X_Train,Y_Train,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 6396 samples, validate on 1600 samples\n",
      "Epoch 1/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 3.8498 - accuracy: 0.1417 - val_loss: 2.1443 - val_accuracy: 0.2131\n",
      "Epoch 2/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 2.1261 - accuracy: 0.2104 - val_loss: 2.0208 - val_accuracy: 0.2550\n",
      "Epoch 3/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 2.0551 - accuracy: 0.2319 - val_loss: 1.9779 - val_accuracy: 0.2556\n",
      "Epoch 4/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 2.0121 - accuracy: 0.2461 - val_loss: 1.9237 - val_accuracy: 0.3081\n",
      "Epoch 5/100\n",
      "6396/6396 [==============================] - 7s 1ms/step - loss: 1.9853 - accuracy: 0.2609 - val_loss: 1.9155 - val_accuracy: 0.2969\n",
      "Epoch 6/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.9421 - accuracy: 0.2703 - val_loss: 1.8615 - val_accuracy: 0.3338\n",
      "Epoch 7/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.9098 - accuracy: 0.2780 - val_loss: 1.8543 - val_accuracy: 0.3313\n",
      "Epoch 8/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.8825 - accuracy: 0.2830 - val_loss: 1.8314 - val_accuracy: 0.3225\n",
      "Epoch 9/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.8725 - accuracy: 0.3013 - val_loss: 1.8111 - val_accuracy: 0.3475\n",
      "Epoch 10/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.8238 - accuracy: 0.3049 - val_loss: 1.7449 - val_accuracy: 0.3494\n",
      "Epoch 11/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.7986 - accuracy: 0.3157 - val_loss: 1.7196 - val_accuracy: 0.3613\n",
      "Epoch 12/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.7603 - accuracy: 0.3310 - val_loss: 1.6904 - val_accuracy: 0.3769\n",
      "Epoch 13/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.7241 - accuracy: 0.3477 - val_loss: 1.6638 - val_accuracy: 0.3938\n",
      "Epoch 14/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.7019 - accuracy: 0.3629 - val_loss: 1.6550 - val_accuracy: 0.4075\n",
      "Epoch 15/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.6721 - accuracy: 0.3726 - val_loss: 1.6277 - val_accuracy: 0.4050\n",
      "Epoch 16/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.6674 - accuracy: 0.3774 - val_loss: 1.5936 - val_accuracy: 0.4206\n",
      "Epoch 17/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.6434 - accuracy: 0.3870 - val_loss: 1.5769 - val_accuracy: 0.4231\n",
      "Epoch 18/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.6014 - accuracy: 0.3981 - val_loss: 1.5754 - val_accuracy: 0.4350\n",
      "Epoch 19/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.5980 - accuracy: 0.3993 - val_loss: 1.5688 - val_accuracy: 0.4406\n",
      "Epoch 20/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.5903 - accuracy: 0.4003 - val_loss: 1.5788 - val_accuracy: 0.4419\n",
      "Epoch 21/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.5681 - accuracy: 0.4071 - val_loss: 1.5460 - val_accuracy: 0.4406\n",
      "Epoch 22/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.5417 - accuracy: 0.4143 - val_loss: 1.4977 - val_accuracy: 0.4737\n",
      "Epoch 23/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.5371 - accuracy: 0.4204 - val_loss: 1.4900 - val_accuracy: 0.4744\n",
      "Epoch 24/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.5316 - accuracy: 0.4185 - val_loss: 1.4761 - val_accuracy: 0.4762\n",
      "Epoch 25/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.5138 - accuracy: 0.4317 - val_loss: 1.4725 - val_accuracy: 0.4706\n",
      "Epoch 26/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.4908 - accuracy: 0.4351 - val_loss: 1.4486 - val_accuracy: 0.4881\n",
      "Epoch 27/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.4825 - accuracy: 0.4342 - val_loss: 1.4475 - val_accuracy: 0.4638\n",
      "Epoch 28/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.4669 - accuracy: 0.4356 - val_loss: 1.4608 - val_accuracy: 0.4919\n",
      "Epoch 29/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.4582 - accuracy: 0.4392 - val_loss: 1.4162 - val_accuracy: 0.4894\n",
      "Epoch 30/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.4345 - accuracy: 0.4525 - val_loss: 1.4010 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.4371 - accuracy: 0.4475 - val_loss: 1.4066 - val_accuracy: 0.4963\n",
      "Epoch 32/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.4247 - accuracy: 0.4587 - val_loss: 1.3891 - val_accuracy: 0.4956\n",
      "Epoch 33/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.4042 - accuracy: 0.4637 - val_loss: 1.4072 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.4057 - accuracy: 0.4631 - val_loss: 1.3919 - val_accuracy: 0.5075\n",
      "Epoch 35/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.3909 - accuracy: 0.4681 - val_loss: 1.4095 - val_accuracy: 0.4944\n",
      "Epoch 36/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.3912 - accuracy: 0.4742 - val_loss: 1.3924 - val_accuracy: 0.4956\n",
      "Epoch 37/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.3724 - accuracy: 0.4683 - val_loss: 1.3693 - val_accuracy: 0.5013\n",
      "Epoch 38/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.3564 - accuracy: 0.4792 - val_loss: 1.4045 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.3495 - accuracy: 0.4761 - val_loss: 1.3832 - val_accuracy: 0.5231\n",
      "Epoch 40/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.3369 - accuracy: 0.4817 - val_loss: 1.3353 - val_accuracy: 0.5194\n",
      "Epoch 41/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.3235 - accuracy: 0.4875 - val_loss: 1.3349 - val_accuracy: 0.5150\n",
      "Epoch 42/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.3155 - accuracy: 0.4970 - val_loss: 1.3343 - val_accuracy: 0.5206\n",
      "Epoch 43/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.3073 - accuracy: 0.4977 - val_loss: 1.3408 - val_accuracy: 0.5200\n",
      "Epoch 44/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.2905 - accuracy: 0.5027 - val_loss: 1.3475 - val_accuracy: 0.5225\n",
      "Epoch 45/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.2786 - accuracy: 0.5014 - val_loss: 1.3281 - val_accuracy: 0.5225\n",
      "Epoch 46/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.2794 - accuracy: 0.5105 - val_loss: 1.3217 - val_accuracy: 0.5200\n",
      "Epoch 47/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.2746 - accuracy: 0.5142 - val_loss: 1.3009 - val_accuracy: 0.5231\n",
      "Epoch 48/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.2650 - accuracy: 0.5131 - val_loss: 1.3071 - val_accuracy: 0.5312\n",
      "Epoch 49/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.2678 - accuracy: 0.5184 - val_loss: 1.3260 - val_accuracy: 0.5250\n",
      "Epoch 50/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.2365 - accuracy: 0.5228 - val_loss: 1.2990 - val_accuracy: 0.5337\n",
      "Epoch 51/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.2181 - accuracy: 0.5342 - val_loss: 1.2812 - val_accuracy: 0.5381\n",
      "Epoch 52/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.2172 - accuracy: 0.5299 - val_loss: 1.2874 - val_accuracy: 0.5331\n",
      "Epoch 53/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.1995 - accuracy: 0.5378 - val_loss: 1.2800 - val_accuracy: 0.5456\n",
      "Epoch 54/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.1964 - accuracy: 0.5338 - val_loss: 1.2668 - val_accuracy: 0.5525\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6396/6396 [==============================] - 7s 1ms/step - loss: 1.2016 - accuracy: 0.5377 - val_loss: 1.2520 - val_accuracy: 0.5437\n",
      "Epoch 56/100\n",
      "6396/6396 [==============================] - 7s 1ms/step - loss: 1.1758 - accuracy: 0.5521 - val_loss: 1.2607 - val_accuracy: 0.5469\n",
      "Epoch 57/100\n",
      "6396/6396 [==============================] - 7s 1ms/step - loss: 1.1837 - accuracy: 0.5442 - val_loss: 1.2599 - val_accuracy: 0.5450\n",
      "Epoch 58/100\n",
      "6396/6396 [==============================] - 7s 1ms/step - loss: 1.1568 - accuracy: 0.5530 - val_loss: 1.2732 - val_accuracy: 0.5469\n",
      "Epoch 59/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.1497 - accuracy: 0.5624 - val_loss: 1.2712 - val_accuracy: 0.5419\n",
      "Epoch 60/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.1365 - accuracy: 0.5624 - val_loss: 1.2786 - val_accuracy: 0.5337\n",
      "Epoch 61/100\n",
      "6396/6396 [==============================] - 7s 1ms/step - loss: 1.1469 - accuracy: 0.5527 - val_loss: 1.2536 - val_accuracy: 0.5600\n",
      "Epoch 62/100\n",
      "6396/6396 [==============================] - 7s 1ms/step - loss: 1.1252 - accuracy: 0.5689 - val_loss: 1.2665 - val_accuracy: 0.5531\n",
      "Epoch 63/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.1093 - accuracy: 0.5761 - val_loss: 1.2382 - val_accuracy: 0.5525\n",
      "Epoch 64/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.0973 - accuracy: 0.5772 - val_loss: 1.2404 - val_accuracy: 0.5581\n",
      "Epoch 65/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.0990 - accuracy: 0.5782 - val_loss: 1.2858 - val_accuracy: 0.5556\n",
      "Epoch 66/100\n",
      "6396/6396 [==============================] - 9s 1ms/step - loss: 1.0755 - accuracy: 0.5944 - val_loss: 1.2331 - val_accuracy: 0.5619\n",
      "Epoch 67/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.0779 - accuracy: 0.5879 - val_loss: 1.2384 - val_accuracy: 0.5663\n",
      "Epoch 68/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.0741 - accuracy: 0.5885 - val_loss: 1.2238 - val_accuracy: 0.5731\n",
      "Epoch 69/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.0537 - accuracy: 0.5955 - val_loss: 1.2300 - val_accuracy: 0.5675\n",
      "Epoch 70/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.0642 - accuracy: 0.5907 - val_loss: 1.2587 - val_accuracy: 0.5719\n",
      "Epoch 71/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.0328 - accuracy: 0.6054 - val_loss: 1.2357 - val_accuracy: 0.5744\n",
      "Epoch 72/100\n",
      "6396/6396 [==============================] - 9s 1ms/step - loss: 1.0238 - accuracy: 0.6049 - val_loss: 1.2434 - val_accuracy: 0.5606\n",
      "Epoch 73/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.0202 - accuracy: 0.6087 - val_loss: 1.2506 - val_accuracy: 0.5694\n",
      "Epoch 74/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.0209 - accuracy: 0.6110 - val_loss: 1.2093 - val_accuracy: 0.5719\n",
      "Epoch 75/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.0050 - accuracy: 0.6182 - val_loss: 1.2364 - val_accuracy: 0.5738\n",
      "Epoch 76/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.0044 - accuracy: 0.6124 - val_loss: 1.2014 - val_accuracy: 0.5838\n",
      "Epoch 77/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 1.0047 - accuracy: 0.6154 - val_loss: 1.2437 - val_accuracy: 0.5731\n",
      "Epoch 78/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.9894 - accuracy: 0.6238 - val_loss: 1.2130 - val_accuracy: 0.5775\n",
      "Epoch 79/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.9849 - accuracy: 0.6230 - val_loss: 1.1984 - val_accuracy: 0.5931\n",
      "Epoch 80/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.9679 - accuracy: 0.6306 - val_loss: 1.2128 - val_accuracy: 0.5894\n",
      "Epoch 81/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.9534 - accuracy: 0.6343 - val_loss: 1.2377 - val_accuracy: 0.5788\n",
      "Epoch 82/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.9746 - accuracy: 0.6280 - val_loss: 1.2499 - val_accuracy: 0.5894\n",
      "Epoch 83/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.9518 - accuracy: 0.6426 - val_loss: 1.1971 - val_accuracy: 0.5900\n",
      "Epoch 84/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.9514 - accuracy: 0.6431 - val_loss: 1.2076 - val_accuracy: 0.5844\n",
      "Epoch 85/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.9461 - accuracy: 0.6384 - val_loss: 1.1989 - val_accuracy: 0.5950\n",
      "Epoch 86/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.9244 - accuracy: 0.6513 - val_loss: 1.1934 - val_accuracy: 0.6000\n",
      "Epoch 87/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.9293 - accuracy: 0.6388 - val_loss: 1.2018 - val_accuracy: 0.5931\n",
      "Epoch 88/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.9002 - accuracy: 0.6578 - val_loss: 1.2131 - val_accuracy: 0.5869\n",
      "Epoch 89/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.9167 - accuracy: 0.6526 - val_loss: 1.2124 - val_accuracy: 0.5831\n",
      "Epoch 90/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.9105 - accuracy: 0.6477 - val_loss: 1.2237 - val_accuracy: 0.5894\n",
      "Epoch 91/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.9044 - accuracy: 0.6488 - val_loss: 1.2189 - val_accuracy: 0.5906\n",
      "Epoch 92/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.8756 - accuracy: 0.6660 - val_loss: 1.2001 - val_accuracy: 0.5994\n",
      "Epoch 93/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.8850 - accuracy: 0.6620 - val_loss: 1.2070 - val_accuracy: 0.5994\n",
      "Epoch 94/100\n",
      "6396/6396 [==============================] - 9s 1ms/step - loss: 0.8898 - accuracy: 0.6653 - val_loss: 1.1907 - val_accuracy: 0.6094\n",
      "Epoch 95/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.8767 - accuracy: 0.6631 - val_loss: 1.2067 - val_accuracy: 0.5981\n",
      "Epoch 96/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.8804 - accuracy: 0.6646 - val_loss: 1.2069 - val_accuracy: 0.6019\n",
      "Epoch 97/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.8655 - accuracy: 0.6759 - val_loss: 1.2049 - val_accuracy: 0.6075\n",
      "Epoch 98/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.8731 - accuracy: 0.6632 - val_loss: 1.2095 - val_accuracy: 0.6056\n",
      "Epoch 99/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.8622 - accuracy: 0.6637 - val_loss: 1.2020 - val_accuracy: 0.6056\n",
      "Epoch 100/100\n",
      "6396/6396 [==============================] - 8s 1ms/step - loss: 0.8524 - accuracy: 0.6721 - val_loss: 1.2055 - val_accuracy: 0.6006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b6eab6b898>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Training the CNN\n",
    "\n",
    "model.fit(X_Train,Y_Train,validation_data=(X_Valid,Y_Valid),batch_size=64,epochs=100)\n",
    "\n",
    "# Concentrate on validation_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 5,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Pred_onehot=model.predict(X_Test)\n",
    "\n",
    "# Y_Pred single query is a 10 sized array so we need to take the maximum one\n",
    "\n",
    "Y_Pred=[]\n",
    "\n",
    "for i in range(len(Y_Pred_onehot)):\n",
    "    predicted_index=0\n",
    "    maxpred=0\n",
    "    for j in range(10):\n",
    "        if(Y_Pred_onehot[i][j]>maxpred):\n",
    "            maxpred=Y_Pred_onehot[i][j]\n",
    "            predicted_index=j\n",
    "    Y_Pred.append(predicted_index)\n",
    "    \n",
    "Y_Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual genre is pop\n",
      "The predicted genre is pop\n"
     ]
    }
   ],
   "source": [
    "print(\"The actual genre is\",data[\"mapping\"][Y_Test[200]])\n",
    "print(\"The predicted genre is\",data[\"mapping\"][Y_Pred[200]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 270us/step\n",
      "The error and accuracy of the model on test set is 1.2916027841567994 and 0.5839999914169312\n"
     ]
    }
   ],
   "source": [
    "test_error,test_accuracy=model.evaluate(X_Test,Y_Test)\n",
    "print(\"The error and accuracy of the model on test set is\",test_error,\"and\",test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
